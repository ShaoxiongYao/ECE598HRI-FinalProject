{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b647dd5",
   "metadata": {},
   "source": [
    "# Camera Calibration Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8743ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aefd8b",
   "metadata": {},
   "source": [
    "## Image collection\n",
    "Inspired by https://stackoverflow.com/questions/34588464/python-how-to-capture-image-from-webcam-on-click-using-opencv\n",
    "\n",
    "6 -> torso\n",
    "14-> left\n",
    "22 -> right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e41ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import scipy.optimize as sopt\n",
    "from klampt.math import se3,so3\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "\n",
    "import open3d as o3d\n",
    "from open3d_calibration import load_pc_dict\n",
    "from calibration_utils import load_cam_K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_1080p(cap):\n",
    "    cap.set(3, 1280)\n",
    "    cap.set(4, 720)\n",
    "\n",
    "cam1 = cv2.VideoCapture(14)\n",
    "make_1080p(cam1)\n",
    "cam2 = cv2.VideoCapture(22)\n",
    "make_1080p(cam2)\n",
    "cam3 = cv2.VideoCapture(6)\n",
    "make_1080p(cam3)\n",
    "cam_dict = {'realsense_left':cam1,'realsense_right':cam2,'realsense_torso':cam3}\n",
    "curr_frame = {'realsense_left':[],'realsense_right':[],'realsense_torso':[]}\n",
    "for i in cam_dict.keys():\n",
    "    cv2.namedWindow(i)\n",
    "\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    for camera in cam_dict.keys():\n",
    "        cam = cam_dict[camera]\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"failed to grab frame\")\n",
    "            break\n",
    "        \n",
    "        cv2.imshow(camera, cv2.resize(frame, (640,480)))\n",
    "        curr_frame.update({camera:frame})\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        for camera in cam_dict.keys():\n",
    "            img_name = \"./Calibration/data/{}/calib_image_frame_{}.png\".format(camera,img_counter)\n",
    "            cv2.imwrite(img_name, curr_frame[camera])\n",
    "            print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "\n",
    "for camera in cam_dict.keys():\n",
    "    cam_dict[camera].release()\n",
    "# cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4898f9",
   "metadata": {},
   "source": [
    "## intrinsic calibration:\n",
    "following: https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9648957",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "empty_dict = {'realsense_left':[],'realsense_right':[],'realsense_torso':[]}\n",
    "# termination criteria\n",
    "\n",
    "horizontal = 8\n",
    "vertical = 6\n",
    "size = 0.108\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((horizontal*vertical,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:horizontal,0:vertical].T.reshape(-1,2)*size \n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints =  deepcopy(empty_dict)\n",
    "imgpoints =  deepcopy(empty_dict) # 2d points in image plane.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acab466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_dict = deepcopy(empty_dict)\n",
    "for camera in ok_dict.keys():\n",
    "    images = sorted(glob.glob('./Calibration/data/{}/calib_image_frame_*.png'.format(camera)))\n",
    "    for fname in tqdm(images):\n",
    "        img = cv.imread(fname)\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    #     cv.imshow('webcam', gray)\n",
    "    #     cv.waitKey()\n",
    "        # Find the chess board corners\n",
    "        ret, corners = cv.findChessboardCorners(gray, (horizontal,vertical), None)\n",
    "        ok_dict[camera].append(ret)\n",
    "    #         cv.imshow('img', img)\n",
    "    #         cv.waitKey(50)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_filter = np.zeros(len(ok_dict[list(ok_dict.keys())[0]]))\n",
    "final_filter[:] = True\n",
    "for i in ok_dict.keys():\n",
    "    final_filter = np.logical_and(final_filter,ok_dict[i])\n",
    "final_filter.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca65b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_dict = deepcopy(empty_dict)\n",
    "\n",
    "for camera in ok_dict.keys():\n",
    "    images = np.array(sorted(glob.glob('./Calibration/data/{}/calib_image_frame_*.png'.format(camera))))\n",
    "    images = images[final_filter]\n",
    "    for fname in tqdm(images):\n",
    "        img = cv.imread(fname)\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    #     cv.imshow('webcam', gray)\n",
    "    #     cv.waitKey()\n",
    "        # Find the chess board corners\n",
    "        ret, corners = cv.findChessboardCorners(gray, (horizontal,vertical), None)\n",
    "        ok_dict[camera].append(ret)\n",
    "    #     # If found, add object points, image points (after refining them)\n",
    "        if ret == True:\n",
    "            objpoints[camera].append(objp)\n",
    "            corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "            imgpoints[camera].append(corners)\n",
    "            # Draw and display the corners\n",
    "            cv.drawChessboardCorners(img, (horizontal,vertical), corners2, ret)\n",
    "#             cv.imshow('img', img)\n",
    "#             cv.waitKey(100)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3797f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrations = deepcopy(empty_dict)\n",
    "for camera in ok_dict.keys():\n",
    "    \n",
    "    ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints[camera], imgpoints[camera], gray.shape[::-1], None, None)\n",
    "    calibrations.update({camera:[mtx,dist,rvecs,tvecs]})\n",
    "    mean_error = 0\n",
    "    for i in range(len(objpoints)):\n",
    "        imgpoints2, _ = cv.projectPoints(objpoints[camera][i], rvecs[i], tvecs[i], mtx, dist)\n",
    "        error = cv.norm(imgpoints[camera][i], imgpoints2, cv.NORM_L2)/len(imgpoints2)\n",
    "        mean_error += error\n",
    "    print( \"total error for camera = {}: {}\".format(camera,mean_error/len(objpoints)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b588e2",
   "metadata": {},
   "source": [
    "## Extrinsic Calibration\n",
    "from: https://docs.opencv.org/4.x/d7/d53/tutorial_py_pose.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e78491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img, corners, imgpts):\n",
    "    corner = tuple(corners[0].ravel().astype(int))\n",
    "    img = cv.line(img, corner, tuple(imgpts[0].ravel().astype(np.int)), (255,0,0), 5)\n",
    "    img = cv.line(img, corner, tuple(imgpts[1].ravel().astype(np.int)), (0,255,0), 5)\n",
    "    img = cv.line(img, corner, tuple(imgpts[2].ravel().astype(np.int)), (0,0,255), 5)\n",
    "    return img\n",
    "\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "objp = np.zeros((horizontal*vertical,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:horizontal,0:vertical].T.reshape(-1,2)*size\n",
    "axis = np.float32([[2*size,0,0], [0,2*size,0], [0,0,-2*size]]).reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e418bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner = deepcopy(empty_dict)\n",
    "rs = deepcopy(empty_dict)\n",
    "ts = deepcopy(empty_dict)\n",
    "\n",
    "for camera in ok_dict.keys():\n",
    "    images = np.array(sorted(glob.glob('./Calibration/data/{}/calib_image_frame_*.png'.format(camera))))\n",
    "    images = images[final_filter]\n",
    "    mtx, dist, rvecs, tvecs = calibrations[camera]\n",
    "    for fname in tqdm(images):\n",
    "        \n",
    "        img = cv.imread(fname)\n",
    "        gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv.findChessboardCorners(gray, (horizontal,vertical),None)\n",
    "        if ret == True:\n",
    "            corners2 = cv.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "            # Find the rotation and translation vectors.\n",
    "            ret,rvecs, tvecs = cv.solvePnP(objp, corners2, mtx, dist)\n",
    "            rs[camera].append(rvecs)\n",
    "            ts[camera].append(tvecs)\n",
    "            # project 3D points to image plane\n",
    "            imgpts, jac = cv.projectPoints(axis, rvecs, tvecs, mtx, dist)\n",
    "            img = draw(img,corners2,imgpts)\n",
    "            cv.imshow('img',img)\n",
    "            k = cv.waitKey(0) & 0xFF\n",
    "            if k == ord('l'):\n",
    "                corner[camera].append('l')\n",
    "            else:\n",
    "                corner[camera].append('r')\n",
    "#         if k == ord('s'):\n",
    "#             cv.imwrite(fname[:6]+'.png', img)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6dfa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_mask =  np.zeros(len(corner[list(ok_dict.keys())[0]]))\n",
    "corner_mask[:] = True\n",
    "for i in range(len(corner.keys())-1):\n",
    "    this = list(corner.keys())[i]\n",
    "    that = list(corner.keys())[i+1]\n",
    "    equal = corner[this] == corner[that]\n",
    "    corner_mask = np.logical_and(corner_mask,equal)\n",
    "# corner_mask = np.array(corner['realsense']) == np.array(corner['webcam'])\n",
    "compatibility_mask = final_filter.copy()\n",
    "compatibility_mask[:] = False\n",
    "compatibility_mask[final_filter] = corner_mask\n",
    "final_mask = np.logical_and(final_filter,compatibility_mask)\n",
    "final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee0131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_rs = deepcopy(empty_dict)\n",
    "m_ts = deepcopy(empty_dict)\n",
    "\n",
    "for camera in ts.keys():\n",
    "    m_rs.update({camera:np.array(rs[camera])[corner_mask].reshape(-1,3).tolist()})\n",
    "    m_ts.update({camera:(np.array((ts[camera]))[corner_mask].reshape(-1,3)).tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9012221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as sopt\n",
    "from klampt.math import se3,so3\n",
    "from itertools import combinations\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_error(x,*args):\n",
    "    \"\"\"\n",
    "    x:[0:6] pos + rotvec of one camera w.r.t. to the other\n",
    "    \"\"\"\n",
    "    x = x.tolist()\n",
    "    R_w_r = so3.from_rotation_vector(x[3:6])\n",
    "#     print(R_w_r)\n",
    "    T_w_r = x[:3]\n",
    "    m1 = args[0]\n",
    "    m2 = args[1]\n",
    "#     print(T_w_r)\n",
    "    errors = []\n",
    "    for i,pt in enumerate(m1):\n",
    "#         print(pt)\n",
    "        pred_pt = se3.apply((R_w_r,T_w_r),pt)\n",
    "        errors.append(np.linalg.norm(np.array(pred_pt)-np.array(m2[i])))\n",
    "    \n",
    "    return np.mean(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff2542",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = {}\n",
    "for pair in combinations(m_rs.keys(), r =2):\n",
    "    source = pair[0]\n",
    "    destination = pair[1]\n",
    "    res = sopt.minimize(transformation_error,np.array([0,0,0,1,0,0]),args = (m_ts[source],m_ts[destination]),tol = 0.0000001, options = {'maxiter':100000,'disp':True})\n",
    "    transforms.update({tuple(pair):res.x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ed240",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms\n",
    "pickle.dump(transforms,open('./transforms.p','wb'))\n",
    "pickle.dump(calibrations,open('./intrinsic_calibrations.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from realsense import RealSenseCamera\n",
    "\n",
    "\n",
    "serial_numbers = {'realsense_left':\"f0220315\",'realsense_right':\"f0271386\",'realsense_torso':\"f0190400\"}\n",
    "\n",
    "cams = {'realsense_left':[],'realsense_right':[],'realsense_torso':[]}\n",
    "pt_clouds = deepcopy(cams)\n",
    "\n",
    "for i in serial_numbers.keys():\n",
    "    print(i)\n",
    "    cams.update({i:RealSenseCamera(serial_numbers[i],'L515',{})})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in serial_numbers.keys():\n",
    "    print(\"serial number:\", i)\n",
    "    cams[i].update()\n",
    "    pt_clouds.update({i:cams[i].latest_point_cloud()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76aeb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "1280*720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c64fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_clouds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fae9043",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_dir = 'Calibration/data/point_cloud'\n",
    "for k in pt_clouds.keys():\n",
    "    pcd_fn = pcd_dir+'/'+k+'.npy'\n",
    "    np.save(pcd_fn, pt_clouds[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_dir = 'Calibration/data/point_cloud'\n",
    "keys_list = ['realsense_left','realsense_right','realsense_torso']\n",
    "pcd_dict = load_pc_dict(pcd_dir, keys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e297cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da4b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_raw = o3d.io.read_image(\"Dataset/2022-04-20-15-23-26/cam_left/color/color_1650486207058728343.png\")\n",
    "depth_raw = o3d.io.read_image(\"Dataset/2022-04-20-15-23-26/cam_left/depth/depth_1650486207054997458.png\")\n",
    "\n",
    "left_rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw, \n",
    "                                                                     depth_trunc=10.0,\n",
    "                                                                     convert_rgb_to_intensity=False)\n",
    "print(rgbd_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c770fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_raw = o3d.io.read_image(\"Dataset/2022-04-20-15-23-26/cam_right/color/color_1650486207048106605.png\")\n",
    "depth_raw = o3d.io.read_image(\"Dataset/2022-04-20-15-23-26/cam_right/depth/depth_1650486207045814453.png\")\n",
    "\n",
    "right_rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw, \n",
    "                                                                      depth_trunc=10.0,\n",
    "                                                                      convert_rgb_to_intensity=False)\n",
    "print(rgbd_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb7377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot depth image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('RGB image')\n",
    "plt.imshow(rgbd_image.color)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Depth image')\n",
    "plt.imshow(rgbd_image.depth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1fe4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_fn = 'intrinsic_calibrations.p'\n",
    "cam_K_dict = load_cam_K(K_fn, 1280, 720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925e069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_K_dict['realsense_left'].intrinsic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dir = 'Calibration/data/extrinsics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d74517",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_pcd = o3d.geometry.PointCloud.create_from_rgbd_image(left_rgbd_image, cam_K_dict['realsense_left'], project_valid_depth_only=False)\n",
    "left2torso_E = np.load(trans_dir+'/left2torso.npy')\n",
    "left_pcd.transform(left2torso_E)\n",
    "left_pcd.remove_non_finite_points()\n",
    "\n",
    "right_pcd = o3d.geometry.PointCloud.create_from_rgbd_image(right_rgbd_image, cam_K_dict['realsense_right'], project_valid_depth_only=False)\n",
    "right2torso_E = np.load(trans_dir+'/right2torso.npy')\n",
    "right_pcd.transform(right2torso_E)\n",
    "right_pcd.remove_non_finite_points()\n",
    "\n",
    "o3d.visualization.draw_geometries([left_pcd, right_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12cd048",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run bag2png.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
