{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17734c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import scipy.optimize as sopt\n",
    "from klampt.math import se3,so3\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "from create_point_cloud import load_whole_point_cloud\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f0a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "from collections import deque\n",
    "from queue import Queue\n",
    "from threading import Event, Lock, Thread\n",
    "\n",
    "import cv2\n",
    "\n",
    "from mmpose.apis import (get_track_id, inference_top_down_pose_model,\n",
    "                         init_pose_model, vis_pose_result)\n",
    "from mmpose.core import apply_bugeye_effect, apply_sunglasses_effect\n",
    "from mmpose.utils import StopWatch\n",
    "\n",
    "try:\n",
    "    from mmdet.apis import inference_detector, init_detector\n",
    "    has_mmdet = True\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    has_mmdet = False\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "    psutil_proc = psutil.Process()\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    psutil_proc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42500f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proper_image_paths(unfilled_df,datasets_parent_folder):\n",
    "    filled_df = unfilled_df.copy()\n",
    "    for col in unfilled_df.columns:\n",
    "        if(col.startswith('cam')):\n",
    "            filled_df.loc[:,col] = unfilled_df.loc[:,col].str.replace('{}',datasets_parent_folder)\n",
    "    return filled_df\n",
    "\n",
    "def strip_dataset_parent_folder(filled_df,parent_folder_name):\n",
    "    # post-processing the dataset:\n",
    "    reusable_df = filled_df.copy()\n",
    "    for col in reusable_df.columns:\n",
    "        if(col.startswith('cam')):\n",
    "            tmp1 = reusable_df[col].str.split(parent_folder_name,expand = True).loc[:,1]\n",
    "            tmp1 = '{}/' + tmp1\n",
    "            reusable_df.loc[:,col] = tmp1\n",
    "    return reusable_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a3efacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aligned_dataset(dataset_folder,master_camera = 'cam_torso_depth'):\n",
    "    cam_folders = sorted(glob(dataset_folder+'/*'))\n",
    "\n",
    "    dataset_dict = {}\n",
    "\n",
    "    for cam_folder in cam_folders:\n",
    "        cam_name = cam_folder.split('/')[-1]\n",
    "\n",
    "        color_dataset = sorted(glob('{}/color/*'.format(cam_folder)))\n",
    "        depth_dataset = sorted(glob('{}/depth/*'.format(cam_folder)))\n",
    "\n",
    "        dataset_dict.update({'{}_depth'.format(cam_name):depth_dataset,'{}_color'.format(cam_name):color_dataset})\n",
    "        \n",
    "        dataframes = {}\n",
    "        for i in dataset_dict.keys():\n",
    "            df = pd.DataFrame({'frame':dataset_dict[i]})\n",
    "            timestamps = df.frame.str.split('_',expand = True).iloc[:,-1].str.split('.',expand = True).iloc[:,0].astype(float)\n",
    "            df['timestamps'] = timestamps\n",
    "            df.columns = [i,'timestamps']\n",
    "            dataframes.update({i:df})\n",
    "            \n",
    "    dict_keys = list(dataset_dict.keys())\n",
    "\n",
    "    original_df = dataframes[master_camera]\n",
    "    for i in dict_keys:\n",
    "        if(i != master_camera):\n",
    "            original_df[i] = np.nan\n",
    "\n",
    "    sorted_df = original_df.sort_values(by = 'timestamps')\n",
    "    filled_df = sorted_df.fillna(method= 'ffill',limit = 11)\n",
    "\n",
    "    for i in tqdm(range(original_df.shape[0])):\n",
    "        timestamp = original_df.timestamps[i]\n",
    "        for j in dict_keys:\n",
    "            if(j != master_camera):\n",
    "                td = np.min(np.abs(dataframes[j].timestamps-timestamp))/1000000000\n",
    "                index = np.argmin(np.abs(dataframes[j].timestamps-timestamp))\n",
    "                if(td < 1/60):\n",
    "                    original_df.loc[i,j] = dataframes[j].loc[index,j]\n",
    "\n",
    "    original_df.shape\n",
    "\n",
    "    clean_df = original_df.dropna()\n",
    "    clean_df.reset_index(drop = True, inplace = True)\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103cec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_pose(frame, mmdet_results,det_score_thr = 0.3):\n",
    "\n",
    "    pose_results_list = []\n",
    "    for model_info, pose_history in zip(pose_model_list,\n",
    "                                        pose_history_list):\n",
    "        model_name = model_info['name']\n",
    "        pose_model = model_info['model']\n",
    "        cat_ids = model_info['cat_ids']\n",
    "        pose_results_last = pose_history['pose_results_last']\n",
    "        next_id = pose_history['next_id']\n",
    "\n",
    "        # process mmdet results\n",
    "        det_results = process_mmdet_results(\n",
    "            mmdet_results,\n",
    "            class_names=det_model.CLASSES,\n",
    "            cat_ids=cat_ids)\n",
    "\n",
    "        # inference pose model\n",
    "        dataset_name = pose_model.cfg.data['test']['type']\n",
    "        pose_results, _ = inference_top_down_pose_model(\n",
    "            pose_model,\n",
    "            frame,\n",
    "            det_results,\n",
    "            bbox_thr=det_score_thr,\n",
    "            format='xyxy',\n",
    "            dataset=dataset_name)\n",
    "\n",
    "        pose_results, next_id = get_track_id(\n",
    "            pose_results,\n",
    "            pose_results_last,\n",
    "            next_id,\n",
    "            use_oks=False,\n",
    "            tracking_thr=0.3,\n",
    "            use_one_euro=True,\n",
    "            fps=None)\n",
    "\n",
    "        pose_results_list.append(pose_results)\n",
    "\n",
    "        # update pose history\n",
    "        pose_history['pose_results_last'] = pose_results\n",
    "        pose_history['next_id'] = next_id\n",
    "    return pose_results_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a28205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_detection(frame):\n",
    "    # inference detection\n",
    "    mmdet_results = inference_detector(det_model, frame)\n",
    "    return mmdet_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87da4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mmdet_results(mmdet_results, class_names=None, cat_ids=1):\n",
    "    \"\"\"Process mmdet results to mmpose input format.\n",
    "\n",
    "    Args:\n",
    "        mmdet_results: raw output of mmdet model\n",
    "        class_names: class names of mmdet model\n",
    "        cat_ids (int or List[int]): category id list that will be preserved\n",
    "    Returns:\n",
    "        List[Dict]: detection results for mmpose input\n",
    "    \"\"\"\n",
    "    if isinstance(mmdet_results, tuple):\n",
    "        mmdet_results = mmdet_results[0]\n",
    "\n",
    "    if isinstance(class_names, str):\n",
    "        class_names = (class_names, )\n",
    "\n",
    "    if not isinstance(cat_ids, (list, tuple)):\n",
    "        cat_ids = [cat_ids]\n",
    "\n",
    "    # only keep bboxes of interested classes\n",
    "    bbox_results = [mmdet_results[i - 1] for i in cat_ids]\n",
    "    bboxes = np.vstack(bbox_results)\n",
    "\n",
    "    # get textual labels of classes\n",
    "    labels = np.concatenate([\n",
    "        np.full(bbox.shape[0], i - 1, dtype=np.int32)\n",
    "        for i, bbox in zip(cat_ids, bbox_results)\n",
    "    ])\n",
    "    if class_names is None: \n",
    "        labels = [f'class: {i}' for i in labels]\n",
    "    else:\n",
    "        labels = [class_names[i] for i in labels]\n",
    "\n",
    "    det_results = []\n",
    "    for bbox, label in zip(bboxes, labels):\n",
    "        det_result = dict(bbox=bbox, label=label)\n",
    "        det_results.append(det_result)\n",
    "    return det_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3df3c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_hand_center(hand_points,images_df,cam_side = 'right',trans_dir = './Calibration/data/extrinsics'):\n",
    "    try:\n",
    "        # create grayscale image with white circle (255) on black background (0)\n",
    "        mask = np.zeros(shape = frame.shape[:2],dtype = np.uint8)\n",
    "        hand_points = hand_points[hand_points[:,2] > 0.1]\n",
    "        for point in hand_points:\n",
    "            cv2.circle(mask,(int(point[0]),int(point[1])),3,255,-1)\n",
    "        coordy,coordx = np.where(mask>0)\n",
    "        points = np.ravel_multi_index((coordy,coordx),frame.shape[:2])\n",
    "\n",
    "        color = images_df.loc[index,'cam_{}_color'.format(cam_side)]\n",
    "        depth = images_df.loc[index,'cam_{}_depth'.format(cam_side)]\n",
    "        pcd = load_whole_point_cloud(color,depth,'realsense_{}'.format(cam_side))\n",
    "        hand = pcd.select_by_index(points)\n",
    "        hand.remove_non_finite_points()\n",
    "        E2torso = np.load(trans_dir+f'/right2torso.npy')\n",
    "        result = hand.cluster_dbscan(0.1, 20)\n",
    "        mode = scipy.stats.mode(result)\n",
    "        actual_hand_index = np.where(result == mode.mode[0])[0]\n",
    "        actual_hand = hand.select_by_index(actual_hand_index)\n",
    "        flipped_hand = actual_hand.transform(E2torso)\n",
    "        positions = np.asarray(flipped_hand.points)\n",
    "        return positions.mean(axis = 0)\n",
    "    except Exception as e:\n",
    "        print('missing data due to {}\\n'.format(e))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe75a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "MMPOSE_DIR = '/home/motion/Joao/classes/hri_kdc/final_project/mmpose'\n",
    "det_config = '{}/demo/mmdetection_cfg/ssdlite_mobilenetv2_scratch_600e_coco.py'.format(MMPOSE_DIR)\n",
    "det_checkpoint = 'https://download.openmmlab.com/mmdetection/v2.0/ssd/ssdlite_mobilenetv2_scratch_600e_coco/ssdlite_mobilenetv2_scratch_600e_coco_20210629_110627-974d9307.pth'\n",
    "device = 'cuda:0'\n",
    "enable_human_pose = 1\n",
    "human_pose_config = '{}/configs/wholebody/2d_kpt_sview_rgb_img/topdown_heatmap/coco-wholebody/vipnas_res50_coco_wholebody_256x192_dark.py'.format(MMPOSE_DIR)\n",
    "human_pose_checkpoint = 'https://download.openmmlab.com/mmpose/top_down/vipnas/vipnas_res50_wholebody_256x192_dark-67c0ce35_20211112.pth'\n",
    "human_det_ids = [1]\n",
    "buffer_size = 1\n",
    "display_delay = 0\n",
    "assert has_mmdet, 'Please install mmdet to run the demo.'\n",
    "assert det_config is not None\n",
    "assert det_checkpoint is not None\n",
    "\n",
    "# build detection model\n",
    "det_model = init_detector(\n",
    "    det_config, det_checkpoint, device=device.lower())\n",
    "\n",
    "# build pose models\n",
    "pose_model_list = []\n",
    "if enable_human_pose:\n",
    "    pose_model = init_pose_model(\n",
    "        human_pose_config,\n",
    "        human_pose_checkpoint,\n",
    "        device=device.lower())\n",
    "    model_info = {\n",
    "        'name': 'HumanPose',\n",
    "        'model': pose_model,\n",
    "        'cat_ids': human_det_ids,\n",
    "        'bbox_color': (148, 139, 255),\n",
    "    }\n",
    "    pose_model_list.append(model_info)\n",
    "\n",
    "\n",
    "# store pose history for pose tracking\n",
    "pose_history_list = []\n",
    "\n",
    "for _ in range(len(pose_model_list)):\n",
    "    pose_history_list.append({'pose_results_last': [], 'next_id': 0})\n",
    "    \n",
    "datasets_dir = '/home/motion/data/ECE598/our_dataset'\n",
    "scenes = sorted(glob(datasets_dir + '/*'))\n",
    "\n",
    "dataset_folder = scenes[0]\n",
    "\n",
    "clean_df =  get_aligned_dataset(dataset_folder,master_camera = 'cam_torso_depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da7bc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "right_hand_positions = []\n",
    "left_hand_positions = []\n",
    "\n",
    "for index in tqdm(list(clean_df.index)):\n",
    "    frame = cv2.imread(clean_df.loc[index,'cam_right_color'], cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if(frame is not None):\n",
    "        res = inference_detection(frame)\n",
    "        pose_results = infer_pose(frame,res,det_score_thr = 0.1)\n",
    "        pose_model = pose_model_list[0]['model']\n",
    "        bbox_color = pose_model_list[0]['bbox_color']\n",
    "        dataset_name = pose_model.cfg.data['test']['type']\n",
    "    #     img = vis_pose_result(pose_model,\n",
    "    #                                 frame,\n",
    "    #                                 pose_results[0],\n",
    "    #                                 radius=4,\n",
    "    #                                 thickness=2,\n",
    "    #                                 dataset=dataset_name,\n",
    "    #                                 kpt_score_thr=0.1,\n",
    "    #                                 bbox_color=bbox_color,show = False)\n",
    "        if(len(pose_results[0])>0):\n",
    "            left_hand = pose_results[0][0]['keypoints'][91:112,:]\n",
    "            right_hand = pose_results[0][0]['keypoints'][112:,:]\n",
    "            lhp = find_hand_center(left_hand,clean_df,cam_side = 'right')\n",
    "            rhp = find_hand_center(right_hand,clean_df,cam_side = 'left')\n",
    "            left_hand_positions.append(lhp)\n",
    "            right_hand_positions.append(rhp)\n",
    "    #         plt.scatter(fingers[:,0],fingers[:,1])\n",
    "    #         plt.imshow(frame)\n",
    "    #         plt.show()\n",
    "        else:\n",
    "            left_hand_positions.append(None)\n",
    "            right_hand_positions.append(None)\n",
    "    else:\n",
    "        left_hand_positions.append(None)\n",
    "        right_hand_positions.append(None)\n",
    "#     time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-processing the dataset:\n",
    "# reusable_df = clean_df.copy()\n",
    "# for col in reusable_df.columns:\n",
    "#     if(col.startswith('cam')):\n",
    "#         tmp1 = reusable_df[col].str.split('our_dataset/',expand = True).loc[:,1]\n",
    "#         tmp1 = '{}/' + tmp1\n",
    "#         reusable_df.loc[:,col] = tmp1\n",
    "reusable_df = strip_dataset_parent_folder(clean_df,'our_dataset/')\n",
    "reusable_df['gt_left_hand'] = left_hand_positions\n",
    "reusable_df['gt_right_hand'] = right_hand_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b6598",
   "metadata": {},
   "outputs": [],
   "source": [
    "reusable_df = reusable_df.fillna(method= 'ffill',limit = 11)\n",
    "reusable_df.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1130504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reusable_df.to_pickle('./first_ground_truth_alice_no_sword1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2cad7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pd.read_pickle('./first_ground_truth_alice_no_sword1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "460a0053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motion/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# you can use the function \"get_proper_image_paths\" to fill the placeholder {} in the image paths with the \n",
    "# correct path where you are saving the dataset ima\n",
    "test2 = get_proper_image_paths(test1,'/home/motion/data/ECE598/our_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e34dafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = load_whole_point_cloud(test2.loc[0,'cam_torso_color'],test2.loc[0,'cam_torso_depth'],'realsense_torso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9462f37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cam_torso_depth', 'timestamps', 'cam_left_depth', 'cam_left_color',\n",
       "       'cam_right_depth', 'cam_right_color', 'cam_torso_color', 'gt_left_hand',\n",
       "       'gt_right_hand'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
